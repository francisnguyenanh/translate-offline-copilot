# -*- coding: utf-8 -*-
"""
·ª®ng d·ª•ng Flask qu·∫£n l√Ω tr√≠ch xu·∫•t v√† n·∫°p b·∫£n d·ªãch cho file Excel, PowerPoint v√† Word
"""

import os
import json
import zipfile
import uuid
import shutil
import io
from datetime import datetime, timedelta
from urllib.parse import quote
from flask import Flask, render_template, request, send_file, jsonify, session, redirect, url_for
from werkzeug.utils import secure_filename
from openpyxl import load_workbook
from pptx import Presentation
from docx import Document
from functools import wraps

# Kh·ªüi t·∫°o ·ª©ng d·ª•ng Flask
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 60 * 1024 * 1024  # Gi·ªõi h·∫°n 50MB
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['SECRET_KEY'] = os.urandom(24)  # Secret key cho session
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(hours=8)  # Session timeout 8h

# C√°c ƒë·ªãnh d·∫°ng file ƒë∆∞·ª£c ph√©p
ALLOWED_EXTENSIONS = {'xlsx', 'pptx', 'docx'}

# ƒê·ªçc password t·ª´ file
PASSWORD_FILE = 'password.txt'

# File l∆∞u Prompt Templates
TEMPLATES_FILE = 'prompt_templates.json'

# ==================== HELPER: PROMPT TEMPLATES ====================
def get_default_templates():
    """Tr·∫£ v·ªÅ danh s√°ch template m·∫∑c ƒë·ªãnh"""
    return [
        {
            "id": "formal",
            "name": "D·ªãch ch√≠nh x√°c (Formal)",
            "content": "H√£y d·ªãch c√°c gi√° tr·ªã (values) trong file JSON n√†y sang {TARGET_LANG}.\n\nPhong c√°ch: Ch√≠nh x√°c, chuy√™n nghi·ªáp, d√πng trong t√†i li·ªáu kinh doanh.\n\nQuy t·∫Øc b·∫Øt bu·ªôc:\n1. Gi·ªØ nguy√™n 100% c√°c keys\n2. CH·ªà d·ªãch n·ªôi dung b√™n trong values\n3. KH√îNG d·ªãch t·ª´/c·ª•m t·ª´ ƒë√£ l√† ng√¥n ng·ªØ ƒë√≠ch\n4. KH√îNG d·ªãch m√£ k·ªπ thu·∫≠t, placeholder, t√™n bi·∫øn\n5. KH√îNG d·ªãch s·ªë, ng√†y th√°ng, k√Ω hi·ªáu ƒë·∫∑c bi·ªát\n6. Gi·ªØ nguy√™n format JSON chu·∫©n\n\n‚ö†Ô∏è QUY T·∫Æc v·ªÅ d·∫•u ngo·∫∑c k√©p: CH·ªà d√πng \" (U+0022). KH√îNG d√πng \u201c \u201d \u201e \u201f \u00ab \u00bb\nTr√≠ch d·∫´n: d√πng \u300c \u300dho·∫∑c 'ƒë∆°n'\n\nOutput: Tr·∫£ v·ªÅ ƒê√öNG c·∫•u tr√∫c JSON, KH√îNG th√™m gi·∫£i th√≠ch."
        },
        {
            "id": "casual",
            "name": "D·ªãch t·ª± nhi√™n (Casual)",
            "content": "H√£y d·ªãch c√°c gi√° tr·ªã (values) trong file JSON n√†y sang {TARGET_LANG}.\n\nPhong c√°ch: T·ª± nhi√™n, th√¢n thi·ªán, d·ªÖ ƒë·ªçc - ph√π h·ª£p cho giao di·ªán ng∆∞·ªùi d√πng.\n\nQuy t·∫Øc b·∫Øt bu·ªôc:\n1. Gi·ªØ nguy√™n 100% c√°c keys\n2. CH·ªà d·ªãch n·ªôi dung b√™n trong values\n3. KH√îNG d·ªãch t·ª´/c·ª•m t·ª´ ƒë√£ l√† ng√¥n ng·ªØ ƒë√≠ch\n4. KH√îNG d·ªãch m√£ k·ªπ thu·∫≠t, placeholder, t√™n bi·∫øn\n5. KH√îNG d·ªãch s·ªë, ng√†y th√°ng, k√Ω hi·ªáu ƒë·∫∑c bi·ªát\n6. Gi·ªØ nguy√™n format JSON chu·∫©n\n\n‚ö†Ô∏è QUY T·∫Æc v·ªÅ d·∫•u ngo·∫∑c k√©p: CH·ªà d√πng \" (U+0022). KH√îNG d√πng \u201c \u201d \u201e \u201f \u00ab \u00bb\n\nOutput: Tr·∫£ v·ªÅ ƒê√öNG c·∫•u tr√∫c JSON, KH√îNG th√™m gi·∫£i th√≠ch."
        },
        {
            "id": "technical",
            "name": "D·ªãch k·ªπ thu·∫≠t (Technical)",
            "content": "H√£y d·ªãch c√°c gi√° tr·ªã (values) trong file JSON n√†y sang {TARGET_LANG}.\n\nPhong c√°ch: K·ªπ thu·∫≠t, ch√≠nh x√°c cao, gi·ªØ nguy√™n thu·∫≠t ng·ªØ IT.\n\nQuy t·∫Øc b·∫Øt bu·ªôc:\n1. Gi·ªØ nguy√™n 100% c√°c keys\n2. CH·ªà d·ªãch n·ªôi dung b√™n trong values\n3. KH√îNG d·ªãch t·ª´/c·ª•m t·ª´ ƒë√£ l√† ng√¥n ng·ªØ ƒë√≠ch\n4. KH√îNG d·ªãch placeholder ({0}, %s, $n...), t√™n bi·∫øn\n5. KH√îNG d·ªãch s·ªë, ng√†y th√°ng, k√Ω hi·ªáu ƒë·∫∑c bi·ªát\n6. Gi·ªØ nguy√™n thu·∫≠t ng·ªØ IT ti·∫øng Anh n·∫øu kh√¥ng c√≥ t·ª´ t∆∞∆°ng ƒë∆∞∆°ng ch√≠nh x√°c\n7. Gi·ªØ nguy√™n format JSON chu·∫©n\n\n‚ö†Ô∏è QUY T·∫Æc v·ªÅ d·∫•u ngo·∫∑c k√©p: CH·ªà d√πng \" (U+0022). KH√îNG d√πng \u201c \u201d \u201e \u201f \u00ab \u00bb\n\nOutput: Tr·∫£ v·ªÅ ƒê√öNG c·∫•u tr√∫c JSON, KH√îNG th√™m gi·∫£i th√≠ch."
        }
    ]

def load_templates(lang='default'):
    """ƒê·ªçc prompt templates cho m·ªôt ng√¥n ng·ªØ c·ª• th·ªÉ (fallback v·ªÅ default)"""
    try:
        with open(TEMPLATES_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # T∆∞∆°ng th√≠ch ng∆∞·ª£c: n·∫øu data l√† array th√¨ ƒë√≥ l√† format c≈©
        if isinstance(data, list):
            return data
        return data.get(lang) or data.get('default') or get_default_templates()
    except Exception:
        return get_default_templates()


def build_dedup_data(extracted_data, chunk_size=400):
    """
    G·ªôp c√°c keys c√≥ c√πng value ƒë·ªÉ gi·∫£m s·ªë l∆∞·ª£ng c·∫ßn d·ªãch.
    Returns: (dedup_files, mapping, stats)
      - dedup_files: list of {name, content} ‚Äì c√°c chunk dedup (gi·ªëng format files th∆∞·ªùng)
      - mapping: {dedup_key: [orig_key1, orig_key2, ...]}
      - stats: {total, unique, saved, percent_saved}
    """
    # Group keys by value (gi·ªØ order)
    value_to_keys = {}
    for key, value in extracted_data.items():
        if value not in value_to_keys:
            value_to_keys[value] = []
        value_to_keys[value].append(key)

    # Build dedup dict v√† mapping
    dedup_data = {}
    mapping = {}  # dedup_key ‚Üí [original_keys]
    for idx, (value, keys) in enumerate(value_to_keys.items(), 1):
        dk = f'dedup_{idx}'
        dedup_data[dk] = value
        mapping[dk] = keys

    total = len(extracted_data)
    unique = len(dedup_data)
    saved = total - unique
    percent = round(saved * 100 / total) if total > 0 else 0
    stats = {'total': total, 'unique': unique, 'saved': saved, 'percent_saved': percent}

    # Chia th√†nh c√°c chunk
    items = list(dedup_data.items())
    num_chunks = max(1, (unique + chunk_size - 1) // chunk_size)
    dedup_files = []
    for i in range(num_chunks):
        chunk = dict(items[i * chunk_size:(i + 1) * chunk_size])
        dedup_files.append({
            'name': f'dedup_part{i+1:02d}_of_{num_chunks:02d}.json',
            'content': json.dumps(chunk, ensure_ascii=False, indent=2)
        })

    return dedup_files, mapping, stats


def expand_dedup_data(json_data, session_folder):
    """
    M·ªü r·ªông dedup JSON (dedup_N ‚Üí value) th√†nh keys g·ªëc d·ª±a tr√™n mapping ƒë√£ l∆∞u.
    N·∫øu kh√¥ng t√¨m th·∫•y mapping file th√¨ tr·∫£ v·ªÅ nguy√™n.
    """
    mapping_path = os.path.join(session_folder, 'dedup_mapping.json')
    if not os.path.exists(mapping_path):
        return json_data
    try:
        with open(mapping_path, 'r', encoding='utf-8') as f:
            mapping = json.load(f)
        expanded = {}
        for key, value in json_data.items():
            if key.startswith('dedup_') and key in mapping:
                for orig_key in mapping[key]:
                    expanded[orig_key] = value
            else:
                expanded[key] = value  # key th∆∞·ªùng, gi·ªØ nguy√™n
        return expanded
    except Exception:
        return json_data


def get_password():
    """ƒê·ªçc password t·ª´ file password.txt"""
    try:
        with open(PASSWORD_FILE, 'r', encoding='utf-8') as f:
            return f.read().strip()
    except FileNotFoundError:
        # N·∫øu file kh√¥ng t·ªìn t·∫°i, t·∫°o file v·ªõi password m·∫∑c ƒë·ªãnh
        default_password = 'admin123'
        with open(PASSWORD_FILE, 'w', encoding='utf-8') as f:
            f.write(default_password)
        return default_password

def get_machine_id():
    """L·∫•y ID m√°y (d·ª±a tr√™n UUID node)"""
    return hex(uuid.getnode())

def create_session_id():
    """T·∫°o session ID d·ª±a tr√™n machine ID + timestamp"""
    machine_id = get_machine_id()
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    return f"{machine_id}_{timestamp}"

def get_session_folder():
    """L·∫•y ƒë∆∞·ªùng d·∫´n folder c·ªßa session hi·ªán t·∫°i"""
    if 'session_id' not in session:
        session['session_id'] = create_session_id()
    
    session_folder = os.path.join(app.config['UPLOAD_FOLDER'], session['session_id'])
    os.makedirs(session_folder, exist_ok=True)
    return session_folder

def cleanup_old_sessions():
    """X√≥a t·∫•t c·∫£ folder c·ªßa c√°c phi√™n t·ª´ h√¥m qua tr·ªü v·ªÅ tr∆∞·ªõc"""
    try:
        upload_folder = app.config['UPLOAD_FOLDER']
        if not os.path.exists(upload_folder):
            return
        
        # L·∫•y ng√†y hi·ªán t·∫°i (kh√¥ng c√≥ gi·ªù ph√∫t gi√¢y)
        today = datetime.now().date()
        
        # Duy·ªát qua t·∫•t c·∫£ c√°c folder trong uploads
        for folder_name in os.listdir(upload_folder):
            folder_path = os.path.join(upload_folder, folder_name)
            
            if os.path.isdir(folder_path):
                try:
                    # Parse timestamp t·ª´ t√™n folder (format: machine_YYYYMMDD_HHMMSS)
                    parts = folder_name.split('_')
                    if len(parts) >= 2:
                        date_str = parts[-2]  # YYYYMMDD
                        folder_date = datetime.strptime(date_str, '%Y%m%d').date()
                        
                        # N·∫øu folder t·ª´ h√¥m qua tr·ªü v·ªÅ tr∆∞·ªõc, x√≥a ƒëi
                        if folder_date < today:
                            shutil.rmtree(folder_path)
                            print(f"ƒê√£ x√≥a folder c≈©: {folder_name}")
                except (ValueError, IndexError):
                    # N·∫øu kh√¥ng parse ƒë∆∞·ª£c, b·ªè qua
                    continue
    except Exception as e:
        print(f"L·ªói khi cleanup old sessions: {e}")

def login_required(f):
    """Decorator ƒë·ªÉ y√™u c·∫ßu ƒëƒÉng nh·∫≠p"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'logged_in' not in session:
            # N·∫øu l√† request AJAX/JSON, tr·∫£ v·ªÅ JSON thay v√¨ redirect
            if request.path.startswith('/api') or request.is_json or request.path in ['/extract', '/inject', '/clear-uploads']:
                return jsonify({'error': 'Ch∆∞a ƒëƒÉng nh·∫≠p ho·∫∑c phi√™n ƒë√£ h·∫øt h·∫°n'}), 401
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function

def allowed_file(filename):
    """
    Ki·ªÉm tra xem file c√≥ ph·∫£i ƒë·ªãnh d·∫°ng ƒë∆∞·ª£c ph√©p kh√¥ng
    """
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def set_download_headers(response, display_name, default_ascii_name):
    """Set Content-Disposition h·ªó tr·ª£ t√™n file Unicode (RFC 5987)."""
    encoded_filename = quote(display_name, safe='')
    ascii_filename = secure_filename(display_name) or default_ascii_name
    response.headers['Content-Disposition'] = (
        f"attachment; filename=\"{ascii_filename}\"; filename*=UTF-8''{encoded_filename}"
    )
    return response

# Error Handlers
@app.errorhandler(400)
def bad_request(error):
    """X·ª≠ l√Ω l·ªói 400 Bad Request"""
    if request.path.startswith('/api') or request.is_json or request.path in ['/extract', '/inject', '/clear-uploads']:
        return jsonify({'error': str(error) or 'Y√™u c·∫ßu kh√¥ng h·ª£p l·ªá'}), 400
    return str(error), 400

@app.errorhandler(401)
def unauthorized(error):
    """X·ª≠ l√Ω l·ªói 401 Unauthorized"""
    if request.path.startswith('/api') or request.is_json or request.path in ['/extract', '/inject', '/clear-uploads']:
        return jsonify({'error': 'Ch∆∞a ƒëƒÉng nh·∫≠p ho·∫∑c phi√™n ƒë√£ h·∫øt h·∫°n'}), 401
    return redirect(url_for('login'))

@app.errorhandler(404)
def not_found(error):
    """X·ª≠ l√Ω l·ªói 404 Not Found"""
    if request.path.startswith('/api') or request.is_json:
        return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y t√†i nguy√™n'}), 404
    return str(error), 404

@app.errorhandler(413)
def request_entity_too_large(error):
    """X·ª≠ l√Ω l·ªói 413 Request Entity Too Large"""
    return jsonify({'error': 'File qu√° l·ªõn. Gi·ªõi h·∫°n 50MB'}), 413

@app.errorhandler(500)
def internal_server_error(error):
    """X·ª≠ l√Ω l·ªói 500 Internal Server Error"""
    if request.path.startswith('/api') or request.is_json or request.path in ['/extract', '/inject', '/clear-uploads']:
        return jsonify({'error': f'L·ªói m√°y ch·ªß: {str(error)}'}), 500
    return str(error), 500

def extract_text_from_shape(shape, shape_path, extracted_data):
    """
    H√†m ƒë·ªá quy ƒë·ªÉ tr√≠ch xu·∫•t text t·ª´ shape, bao g·ªìm c·∫£ grouped shapes
    shape_path: ƒë∆∞·ªùng d·∫´n ƒë·∫øn shape, v√≠ d·ª• "Shape1" ho·∫∑c "Shape1_2_3"
    """
    # Tr√≠ch xu·∫•t text t·ª´ text frame c·ªßa shape hi·ªán t·∫°i
    if hasattr(shape, "text") and shape.text:
        text_content = shape.text.strip()
        if text_content:  # Ch·ªâ l·∫•y n·ªôi dung kh√¥ng r·ªóng
            extracted_data[shape_path] = text_content
    
    # Tr√≠ch xu·∫•t text t·ª´ table n·∫øu c√≥
    if hasattr(shape, "has_table") and shape.has_table:
        table = shape.table
        for row_idx, row in enumerate(table.rows, start=1):
            for col_idx, cell in enumerate(row.cells, start=1):
                if cell.text.strip():
                    key = f"{shape_path}!Table_R{row_idx}C{col_idx}"
                    extracted_data[key] = cell.text.strip()
    
    # Ki·ªÉm tra xem shape c√≥ ph·∫£i l√† GroupShape kh√¥ng (ch·ª©a c√°c shape con)
    if hasattr(shape, "shapes"):
        # ƒê√¢y l√† grouped shape, duy·ªát qua c√°c shape con
        for child_idx, child_shape in enumerate(shape.shapes, start=1):
            child_path = f"{shape_path}_{child_idx}"
            extract_text_from_shape(child_shape, child_path, extracted_data)

def extract_text_from_pptx(filepath):
    """
    Tr√≠ch xu·∫•t text t·ª´ file PPTX, bao g·ªìm c·∫£ text trong grouped shapes
    Tr·∫£ v·ªÅ dictionary v·ªõi format: {"SlideX!ShapeY": "Content"}
    V·ªõi nested shapes: {"SlideX!ShapeY_Z": "Content"} (Z l√† shape con)
    """
    extracted_data = {}
    prs = Presentation(filepath)
    
    for slide_idx, slide in enumerate(prs.slides, start=1):
        for shape_idx, shape in enumerate(slide.shapes, start=1):
            shape_path = f"Slide{slide_idx}!Shape{shape_idx}"
            extract_text_from_shape(shape, shape_path, extracted_data)
    
    return extracted_data

def inject_text_to_shape(shape, shape_indices, translated_value, is_table_cell=False, table_pos=None):
    """
    H√†m ƒë·ªá quy ƒë·ªÉ n·∫°p text v√†o shape, bao g·ªìm c·∫£ grouped shapes
    shape_indices: list c√°c index ƒë·ªÉ navigate ƒë·∫øn shape ƒë√∫ng, v√≠ d·ª• [2, 3] cho Shape2_3
    is_table_cell: c√≥ ph·∫£i l√† table cell kh√¥ng
    table_pos: tuple (row_idx, col_idx) n·∫øu l√† table cell
    """
    # N·∫øu l√† shape cu·ªëi c√πng trong path
    if len(shape_indices) == 0:
        if is_table_cell and table_pos:
            # N·∫°p v√†o table cell - gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng
            row_idx, col_idx = table_pos
            if hasattr(shape, "has_table") and shape.has_table:
                table = shape.table
                if row_idx < len(table.rows) and col_idx < len(table.rows[row_idx].cells):
                    cell = table.rows[row_idx].cells[col_idx]
                    # Thay th·∫ø text trong t·ª´ng paragraph/run ƒë·ªÉ gi·ªØ ƒë·ªãnh d·∫°ng
                    if cell.text_frame:
                        replace_text_keep_format(cell.text_frame, translated_value)
        else:
            # N·∫°p v√†o text frame c·ªßa shape - gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng
            if hasattr(shape, "text_frame") and shape.text_frame:
                replace_text_keep_format(shape.text_frame, translated_value)
        return True
    
    # Navigate ƒë·∫øn shape con
    if hasattr(shape, "shapes"):
        next_idx = shape_indices[0]
        if next_idx <= len(shape.shapes):
            child_shape = shape.shapes[next_idx - 1]  # Chuy·ªÉn t·ª´ 1-indexed sang 0-indexed
            return inject_text_to_shape(child_shape, shape_indices[1:], translated_value, is_table_cell, table_pos)
    
    return False

def replace_text_keep_format(text_frame, new_text):
    """
    Thay th·∫ø text trong text_frame nh∆∞ng gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng (font, m√†u, g·∫°ch ch√¢n, bold, italic...)
    Chi·∫øn l∆∞·ª£c:
    1. N·∫øu to√†n b·ªô text frame ch·ªâ c√≥ 1 paragraph v√† 1 run -> thay text c·ªßa run ƒë√≥
    2. N·∫øu c√≥ nhi·ªÅu runs/paragraphs -> x√≥a text c·ªßa t·∫•t c·∫£ runs, g√°n text m·ªõi v√†o run ƒë·∫ßu ti√™n v·ªõi ƒë·ªãnh d·∫°ng g·ªëc
    """
    if not text_frame.paragraphs:
        return
    
    # Thu th·∫≠p t·∫•t c·∫£ runs t·ª´ t·∫•t c·∫£ paragraphs
    all_runs = []
    for paragraph in text_frame.paragraphs:
        for run in paragraph.runs:
            all_runs.append(run)
    
    if not all_runs:
        # Kh√¥ng c√≥ run n√†o, t·∫°o m·ªõi
        if text_frame.paragraphs:
            text_frame.paragraphs[0].text = new_text
        return
    
    # L∆∞u ƒë·ªãnh d·∫°ng c·ªßa run ƒë·∫ßu ti√™n
    first_run = all_runs[0]
    
    # X√≥a text c·ªßa t·∫•t c·∫£ runs
    for run in all_runs:
        run.text = ""
    
    # G√°n text m·ªõi v√†o run ƒë·∫ßu ti√™n (gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng)
    first_run.text = new_text

def inject_text_to_pptx(filepath, json_data):
    """
    N·∫°p text ƒë√£ d·ªãch v√†o file PPTX, bao g·ªìm c·∫£ grouped shapes
    """
    prs = Presentation(filepath)
    
    for key, translated_value in json_data.items():
        try:
            # Parse key format: 
            # "SlideX!ShapeY" ho·∫∑c "SlideX!ShapeY_Z" (nested) 
            # ho·∫∑c "SlideX!ShapeY!Table_RxCy" ho·∫∑c "SlideX!ShapeY_Z!Table_RxCy"
            if '!' not in key:
                continue
            
            parts = key.split('!')
            if len(parts) < 2:
                continue
            
            # L·∫•y slide index
            slide_part = parts[0]
            if not slide_part.startswith('Slide'):
                continue
            slide_idx = int(slide_part.replace('Slide', '')) - 1
            
            if slide_idx >= len(prs.slides):
                continue
            
            slide = prs.slides[slide_idx]
            
            # Parse shape path: "Shape2" ho·∫∑c "Shape2_3_1" (nested)
            shape_part = parts[1]
            if not shape_part.startswith('Shape'):
                continue
            
            # T√°ch c√°c indices: "Shape2_3_1" -> [2, 3, 1]
            shape_str = shape_part.replace('Shape', '')
            shape_indices = [int(idx) for idx in shape_str.split('_')]
            
            # L·∫•y shape ƒë·∫ßu ti√™n (top-level shape)
            first_shape_idx = shape_indices[0] - 1  # Chuy·ªÉn sang 0-indexed
            if first_shape_idx >= len(slide.shapes):
                continue
            
            shape = slide.shapes[first_shape_idx]
            
            # Ki·ªÉm tra xem c√≥ ph·∫£i table cell kh√¥ng
            is_table_cell = False
            table_pos = None
            
            if len(parts) == 3 and parts[2].startswith('Table_R'):
                # Parse table cell position
                is_table_cell = True
                table_part = parts[2].replace('Table_R', '').split('C')
                row_idx = int(table_part[0]) - 1
                col_idx = int(table_part[1]) - 1
                table_pos = (row_idx, col_idx)
            
            # Navigate v√† n·∫°p text (b·ªè qua index ƒë·∫ßu ti√™n v√¨ ƒë√£ l·∫•y shape r·ªìi)
            inject_text_to_shape(shape, shape_indices[1:], translated_value, is_table_cell, table_pos)
            
        except (ValueError, IndexError, AttributeError) as e:
            # B·ªè qua c√°c key kh√¥ng h·ª£p l·ªá
            continue
    
    return prs

def extract_text_from_docx(filepath):
    """
    Tr√≠ch xu·∫•t text t·ª´ file DOCX, bao g·ªìm paragraphs, tables, headers, footers
    Tr·∫£ v·ªÅ dictionary v·ªõi format:
    - Paragraphs: {"ParagraphX": "Content"}
    - Tables: {"TableX!RyC z": "Content"}
    - Headers: {"Header_SectionX!ParagraphY": "Content"}
    - Footers: {"Footer_SectionX!ParagraphY": "Content"}
    """
    extracted_data = {}
    doc = Document(filepath)
    
    # 1. Tr√≠ch xu·∫•t text t·ª´ c√°c paragraph th√¥ng th∆∞·ªùng (kh√¥ng trong table)
    paragraph_idx = 0
    for para in doc.paragraphs:
        text_content = para.text.strip()
        if text_content:  # Ch·ªâ l·∫•y paragraph kh√¥ng r·ªóng
            paragraph_idx += 1
            key = f"Paragraph{paragraph_idx}"
            extracted_data[key] = text_content
    
    # 2. Tr√≠ch xu·∫•t text t·ª´ c√°c b·∫£ng
    for table_idx, table in enumerate(doc.tables, start=1):
        for row_idx, row in enumerate(table.rows, start=1):
            for col_idx, cell in enumerate(row.cells, start=1):
                text_content = cell.text.strip()
                if text_content:
                    key = f"Table{table_idx}!R{row_idx}C{col_idx}"
                    extracted_data[key] = text_content
    
    # 3. Tr√≠ch xu·∫•t text t·ª´ headers
    for section_idx, section in enumerate(doc.sections, start=1):
        header = section.header
        for para_idx, para in enumerate(header.paragraphs, start=1):
            text_content = para.text.strip()
            if text_content:
                key = f"Header_Section{section_idx}!Paragraph{para_idx}"
                extracted_data[key] = text_content
        
        # Tr√≠ch xu·∫•t t·ª´ table trong header (n·∫øu c√≥)
        for table_idx, table in enumerate(header.tables, start=1):
            for row_idx, row in enumerate(table.rows, start=1):
                for col_idx, cell in enumerate(row.cells, start=1):
                    text_content = cell.text.strip()
                    if text_content:
                        key = f"Header_Section{section_idx}!Table{table_idx}!R{row_idx}C{col_idx}"
                        extracted_data[key] = text_content
    
    # 4. Tr√≠ch xu·∫•t text t·ª´ footers
    for section_idx, section in enumerate(doc.sections, start=1):
        footer = section.footer
        for para_idx, para in enumerate(footer.paragraphs, start=1):
            text_content = para.text.strip()
            if text_content:
                key = f"Footer_Section{section_idx}!Paragraph{para_idx}"
                extracted_data[key] = text_content
        
        # Tr√≠ch xu·∫•t t·ª´ table trong footer (n·∫øu c√≥)
        for table_idx, table in enumerate(footer.tables, start=1):
            for row_idx, row in enumerate(table.rows, start=1):
                for col_idx, cell in enumerate(row.cells, start=1):
                    text_content = cell.text.strip()
                    if text_content:
                        key = f"Footer_Section{section_idx}!Table{table_idx}!R{row_idx}C{col_idx}"
                        extracted_data[key] = text_content
    
    return extracted_data

def replace_text_keep_format_docx(paragraph, new_text):
    """
    Thay th·∫ø text trong paragraph c·ªßa Word nh∆∞ng gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng (font, m√†u, bold, italic...)
    Chi·∫øn l∆∞·ª£c:
    1. L∆∞u ƒë·ªãnh d·∫°ng c·ªßa run ƒë·∫ßu ti√™n
    2. X√≥a text c·ªßa t·∫•t c·∫£ runs
    3. G√°n text m·ªõi v√†o run ƒë·∫ßu ti√™n (gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng)
    """
    if not paragraph.runs:
        # Kh√¥ng c√≥ run n√†o, t·∫°o m·ªõi
        paragraph.text = new_text
        return
    
    # L∆∞u ƒë·ªãnh d·∫°ng c·ªßa run ƒë·∫ßu ti√™n
    first_run = paragraph.runs[0]
    
    # X√≥a text c·ªßa t·∫•t c·∫£ runs
    for run in paragraph.runs:
        run.text = ""
    
    # G√°n text m·ªõi v√†o run ƒë·∫ßu ti√™n (gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng)
    first_run.text = new_text

def inject_text_to_docx(filepath, json_data):
    """
    N·∫°p text ƒë√£ d·ªãch v√†o file DOCX
    Gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng (font, m√†u, size, bold, italic...)
    """
    doc = Document(filepath)
    
    for key, translated_value in json_data.items():
        try:
            # 1. X·ª≠ l√Ω Paragraph th√¥ng th∆∞·ªùng: "ParagraphX"
            if key.startswith('Paragraph') and '!' not in key:
                para_num = int(key.replace('Paragraph', ''))
                # ƒê·∫øm l·∫°i c√°c paragraph kh√¥ng r·ªóng ƒë·ªÉ map ƒë√∫ng index
                current_para_idx = 0
                for para in doc.paragraphs:
                    if para.text.strip():  # Ch·ªâ ƒë·∫øm paragraph kh√¥ng r·ªóng
                        current_para_idx += 1
                        if current_para_idx == para_num:
                            replace_text_keep_format_docx(para, translated_value)
                            break
            
            # 2. X·ª≠ l√Ω Table: "TableX!RyCz"
            elif key.startswith('Table') and '!' in key and not key.startswith('Header_') and not key.startswith('Footer_'):
                parts = key.split('!')
                if len(parts) != 2:
                    continue
                
                # Parse table index
                table_part = parts[0]
                table_idx = int(table_part.replace('Table', '')) - 1
                
                if table_idx >= len(doc.tables):
                    continue
                
                table = doc.tables[table_idx]
                
                # Parse cell position: "R2C3"
                cell_part = parts[1]
                if not cell_part.startswith('R'):
                    continue
                
                cell_parts = cell_part.replace('R', '').split('C')
                if len(cell_parts) != 2:
                    continue
                
                row_idx = int(cell_parts[0]) - 1
                col_idx = int(cell_parts[1]) - 1
                
                if row_idx < len(table.rows) and col_idx < len(table.rows[row_idx].cells):
                    cell = table.rows[row_idx].cells[col_idx]
                    # Thay th·∫ø text trong paragraph ƒë·∫ßu ti√™n c·ªßa cell
                    if cell.paragraphs:
                        replace_text_keep_format_docx(cell.paragraphs[0], translated_value)
            
            # 3. X·ª≠ l√Ω Header: "Header_SectionX!ParagraphY" ho·∫∑c "Header_SectionX!TableY!RzCw"
            elif key.startswith('Header_Section'):
                parts = key.split('!')
                if len(parts) < 2:
                    continue
                
                # Parse section index
                section_part = parts[0].replace('Header_Section', '')
                section_idx = int(section_part) - 1
                
                if section_idx >= len(doc.sections):
                    continue
                
                header = doc.sections[section_idx].header
                
                # Check if it's a paragraph or table
                if parts[1].startswith('Paragraph'):
                    para_num = int(parts[1].replace('Paragraph', ''))
                    para_idx = 0
                    for para in header.paragraphs:
                        if para.text.strip():
                            para_idx += 1
                            if para_idx == para_num:
                                replace_text_keep_format_docx(para, translated_value)
                                break
                
                elif parts[1].startswith('Table') and len(parts) == 3:
                    # Header table cell
                    table_idx = int(parts[1].replace('Table', '')) - 1
                    if table_idx >= len(header.tables):
                        continue
                    
                    table = header.tables[table_idx]
                    cell_part = parts[2]
                    if not cell_part.startswith('R'):
                        continue
                    
                    cell_parts = cell_part.replace('R', '').split('C')
                    if len(cell_parts) != 2:
                        continue
                    
                    row_idx = int(cell_parts[0]) - 1
                    col_idx = int(cell_parts[1]) - 1
                    
                    if row_idx < len(table.rows) and col_idx < len(table.rows[row_idx].cells):
                        cell = table.rows[row_idx].cells[col_idx]
                        if cell.paragraphs:
                            replace_text_keep_format_docx(cell.paragraphs[0], translated_value)
            
            # 4. X·ª≠ l√Ω Footer: "Footer_SectionX!ParagraphY" ho·∫∑c "Footer_SectionX!TableY!RzCw"
            elif key.startswith('Footer_Section'):
                parts = key.split('!')
                if len(parts) < 2:
                    continue
                
                # Parse section index
                section_part = parts[0].replace('Footer_Section', '')
                section_idx = int(section_part) - 1
                
                if section_idx >= len(doc.sections):
                    continue
                
                footer = doc.sections[section_idx].footer
                
                # Check if it's a paragraph or table
                if parts[1].startswith('Paragraph'):
                    para_num = int(parts[1].replace('Paragraph', ''))
                    para_idx = 0
                    for para in footer.paragraphs:
                        if para.text.strip():
                            para_idx += 1
                            if para_idx == para_num:
                                replace_text_keep_format_docx(para, translated_value)
                                break
                
                elif parts[1].startswith('Table') and len(parts) == 3:
                    # Footer table cell
                    table_idx = int(parts[1].replace('Table', '')) - 1
                    if table_idx >= len(footer.tables):
                        continue
                    
                    table = footer.tables[table_idx]
                    cell_part = parts[2]
                    if not cell_part.startswith('R'):
                        continue
                    
                    cell_parts = cell_part.replace('R', '').split('C')
                    if len(cell_parts) != 2:
                        continue
                    
                    row_idx = int(cell_parts[0]) - 1
                    col_idx = int(cell_parts[1]) - 1
                    
                    if row_idx < len(table.rows) and col_idx < len(table.rows[row_idx].cells):
                        cell = table.rows[row_idx].cells[col_idx]
                        if cell.paragraphs:
                            replace_text_keep_format_docx(cell.paragraphs[0], translated_value)
        
        except (ValueError, IndexError, AttributeError) as e:
            # B·ªè qua c√°c key kh√¥ng h·ª£p l·ªá
            continue
    
    return doc

@app.route('/login', methods=['GET', 'POST'])
def login():
    """Trang ƒëƒÉng nh·∫≠p"""
    if request.method == 'POST':
        password = request.form.get('password', '')
        correct_password = get_password()
        
        if password == correct_password:
            session.permanent = True
            session['logged_in'] = True
            session['session_id'] = create_session_id()
            
            # Cleanup old sessions khi ƒëƒÉng nh·∫≠p
            cleanup_old_sessions()
            
            return redirect(url_for('index'))
        else:
            return render_template('login.html', error='M·∫≠t kh·∫©u kh√¥ng ƒë√∫ng!')
    
    return render_template('login.html')

@app.route('/logout')
def logout():
    """ƒêƒÉng xu·∫•t"""
    # X√≥a folder c·ªßa session hi·ªán t·∫°i
    if 'session_id' in session:
        session_folder = os.path.join(app.config['UPLOAD_FOLDER'], session['session_id'])
        if os.path.exists(session_folder):
            shutil.rmtree(session_folder)
    
    session.clear()
    return redirect(url_for('login'))

@app.route('/')
@login_required
def index():
    """
    Trang ch·ªß hi·ªÉn th·ªã dashboard v·ªõi 2 ch·ª©c nƒÉng Extract v√† Inject
    """
    # Cleanup old sessions m·ªói khi load trang
    cleanup_old_sessions()
    return render_template('index.html')

@app.route('/api/languages', methods=['GET'])
@login_required
def get_languages():
    """
    Tr·∫£ v·ªÅ danh s√°ch ng√¥n ng·ªØ ƒë√≠ch t·ª´ file languages.json
    """
    languages_file = os.path.join(os.path.dirname(__file__), 'languages.json')
    try:
        with open(languages_file, 'r', encoding='utf-8') as f:
            languages = json.load(f)
        return jsonify(languages)
    except FileNotFoundError:
        # Fallback n·∫øu file kh√¥ng t·ªìn t·∫°i
        return jsonify([
            {"code": "ja", "name": "ti·∫øng Nh·∫≠t",  "label": "üáØüáµ Ti·∫øng Nh·∫≠t (Japanese)"},
            {"code": "en", "name": "ti·∫øng Anh",   "label": "üá∫üá∏ Ti·∫øng Anh (English)"},
            {"code": "vi", "name": "ti·∫øng Vi·ªát",  "label": "üáªüá≥ Ti·∫øng Vi·ªát (Vietnamese)"},
            {"code": "zh", "name": "ti·∫øng Trung", "label": "üá®üá≥ Ti·∫øng Trung (Chinese)"},
            {"code": "ko", "name": "ti·∫øng H√†n",   "label": "üá∞üá∑ Ti·∫øng H√†n (Korean)"}
        ])
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ==================== API: PROMPT TEMPLATES ====================

@app.route('/api/templates', methods=['GET'])
@login_required
def api_get_templates():
    """Tr·∫£ v·ªÅ danh s√°ch prompt templates cho ng√¥n ng·ªØ ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh"""
    lang = request.args.get('lang', 'default')
    return jsonify(load_templates(lang))

@app.route('/api/templates', methods=['POST'])
@login_required
def api_save_templates():
    """L∆∞u danh s√°ch prompt templates cho ng√¥n ng·ªØ ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh"""
    lang = request.args.get('lang', 'default')
    new_templates = request.json
    if not isinstance(new_templates, list):
        return jsonify({'error': 'D·ªØ li·ªáu ph·∫£i l√† array'}), 400
    try:
        try:
            with open(TEMPLATES_FILE, 'r', encoding='utf-8') as f:
                all_data = json.load(f)
            if isinstance(all_data, list):
                all_data = {'default': all_data}
        except Exception:
            all_data = {}
        all_data[lang] = new_templates
        with open(TEMPLATES_FILE, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/extract', methods=['POST'])
@login_required
def extract():
    """
    Ch·ª©c nƒÉng 1: Tr√≠ch xu·∫•t c√°c cell ch·ª©a string t·ª´ file Excel, PPTX ho·∫∑c DOCX
    B·ªè qua c√°c cell ch·ª©a s·ªë v√† c√¥ng th·ª©c (b·∫Øt ƒë·∫ßu b·∫±ng '=') trong Excel
    Tr·∫£ v·ªÅ file JSON v·ªõi format: {"SheetName!CellCoordinate": "Content"} ho·∫∑c {"SlideX!ShapeY": "Content"} ho·∫∑c {"ParagraphX": "Content"}
    """
    # Ki·ªÉm tra xem c√≥ file ƒë∆∞·ª£c upload kh√¥ng
    if 'file' not in request.files:
        return jsonify({'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c upload'}), 400
    
    file = request.files['file']
    
    # Ki·ªÉm tra xem file c√≥ ƒë∆∞·ª£c ch·ªçn kh√¥ng
    if file.filename == '':
        return jsonify({'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c ch·ªçn'}), 400
    
    # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
    if not allowed_file(file.filename):
        return jsonify({'error': 'Ch·ªâ ch·∫•p nh·∫≠n file .xlsx, .pptx ho·∫∑c .docx'}), 400
    
    try:
        # L·∫•y session folder
        session_folder = get_session_folder()
        
        # L∆∞u t√™n file g·ªëc (gi·ªØ nguy√™n ti·∫øng Nh·∫≠t, k√Ω t·ª± ƒë·∫∑c bi·ªát)
        original_filename = file.filename
        
        # L·∫•y extension t·ª´ t√™n file g·ªëc
        if '.' in original_filename:
            original_ext = original_filename.rsplit('.', 1)[1].lower()
        else:
            return jsonify({'error': 'T√™n file ph·∫£i c√≥ ƒëu√¥i m·ªü r·ªông (.xlsx ho·∫∑c .pptx)'}), 400
        
        # T·∫°o t√™n file t·∫°m an to√†n ho√†n to√†n t·ª´ timestamp (kh√¥ng d√πng t√™n g·ªëc)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_temp_filename = f"temp_{timestamp}.{original_ext}"
        filepath = os.path.join(session_folder, safe_temp_filename)
        file.save(filepath)
        
        # X√°c ƒë·ªãnh lo·∫°i file v√† tr√≠ch xu·∫•t
        file_ext = original_ext
        
        if file_ext == 'xlsx':
            # M·ªü file Excel b·∫±ng openpyxl
            workbook = load_workbook(filepath)
            
            # Dictionary ƒë·ªÉ l∆∞u k·∫øt qu·∫£
            extracted_data = {}
            
            # Duy·ªát qua t·∫•t c·∫£ c√°c sheet
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                
                # Duy·ªát qua t·∫•t c·∫£ c√°c cell trong sheet
                for row in sheet.iter_rows():
                    for cell in row:
                        # B·ªè qua cell r·ªóng
                        if cell.value is None:
                            continue
                        
                        # Ch·ªâ l·∫•y cell ch·ª©a string
                        if isinstance(cell.value, str):
                            # B·ªè qua c√¥ng th·ª©c (b·∫Øt ƒë·∫ßu b·∫±ng '=')
                            if not cell.value.startswith('='):
                                # T·∫°o key theo format "SheetName!CellCoordinate"
                                key = f"{sheet_name}!{cell.coordinate}"
                                extracted_data[key] = cell.value
            
            # ƒê√≥ng workbook
            workbook.close()
        
        elif file_ext == 'pptx':
            # Tr√≠ch xu·∫•t text t·ª´ PPTX
            extracted_data = extract_text_from_pptx(filepath)
        
        elif file_ext == 'docx':
            # Tr√≠ch xu·∫•t text t·ª´ DOCX
            extracted_data = extract_text_from_docx(filepath)
        
        # T√°ch d·ªØ li·ªáu th√†nh nhi·ªÅu file, m·ªói file 400 c·∫∑p key-value
        CHUNK_SIZE = 400
        data_items = list(extracted_data.items())
        total_items = len(data_items)
        num_files = (total_items + CHUNK_SIZE - 1) // CHUNK_SIZE  # L√†m tr√≤n l√™n
        
        # L·∫•y t√™n file g·ªëc kh√¥ng c√≥ extension (gi·ªØ nguy√™n ti·∫øng Nh·∫≠t)
        base_filename = os.path.splitext(original_filename)[0]
        
        # N·∫øu base_filename r·ªóng, d√πng t√™n m·∫∑c ƒë·ªãnh
        if not base_filename or base_filename.strip() == '':
            base_filename = f"file_{timestamp}"
        # T√™n safe cho filesystem (d√πng timestamp)
        safe_base_filename = f"extracted_{timestamp}"
        
        # T√™n folder trong ZIP (gi·ªØ nguy√™n ti·∫øng Nh·∫≠t)
        folder_name = f"{base_filename}_json_to_translate"
        # T√™n folder t·∫°m trong filesystem (d√πng safe filename)
        safe_folder_name = f"{safe_base_filename}_temp_{timestamp}"
        
        # T·∫°o th∆∞ m·ª•c t·∫°m ƒë·ªÉ ch·ª©a c√°c file JSON (d√πng t√™n safe cho filesystem)
        temp_dir = os.path.join(session_folder, safe_folder_name)
        os.makedirs(temp_dir, exist_ok=True)
        
        json_files = []
        json_display_names = []  # L∆∞u t√™n hi·ªÉn th·ªã v·ªõi ti·∫øng Nh·∫≠t
        
        # T·∫°o c√°c file JSON nh·ªè
        for i in range(num_files):
            start_idx = i * CHUNK_SIZE
            end_idx = min((i + 1) * CHUNK_SIZE, total_items)
            chunk_data = dict(data_items[start_idx:end_idx])
            
            # T√™n file hi·ªÉn th·ªã (gi·ªØ nguy√™n ti·∫øng Nh·∫≠t)
            json_display_name = f"{base_filename}_part{i+1:02d}_of_{num_files:02d}.json"
            json_display_names.append(json_display_name)
            
            # T√™n file an to√†n cho filesystem
            safe_json_filename = f"{safe_base_filename}_part{i+1:02d}.json"
            json_filepath = os.path.join(temp_dir, safe_json_filename)
            
            # L∆∞u d·ªØ li·ªáu v√†o file JSON v·ªõi encoding UTF-8
            with open(json_filepath, 'w', encoding='utf-8') as json_file:
                json.dump(chunk_data, json_file, ensure_ascii=False, indent=2)
            
            json_files.append(json_filepath)
        
        # ƒê·ªçc n·ªôi dung t·ª´ng file JSON ƒë·ªÉ tr·∫£ v·ªÅ cho frontend
        files_data = []
        for idx, json_filepath in enumerate(json_files):
            with open(json_filepath, 'r', encoding='utf-8') as f:
                files_data.append({
                    'name': json_display_names[idx],
                    'content': f.read()
                })
        
        # T·∫°o file ZIP ch·ª©a folder v√† c√°c file JSON
        zip_display_name = f"{base_filename}_json_to_translate.zip"  # T√™n hi·ªÉn th·ªã
        safe_zip_filename = f"{safe_base_filename}_json_{timestamp}.zip"  # T√™n file trong filesystem
        zip_filepath = os.path.join(session_folder, safe_zip_filename)
        
        # D√πng ZIP_STORED ƒë·ªÉ kh√¥ng n√©n file JSON
        with zipfile.ZipFile(zip_filepath, 'w', zipfile.ZIP_STORED) as zipf:
            for idx, json_filepath_item in enumerate(json_files):
                arcname = os.path.join(folder_name, json_display_names[idx])
                zipf.write(json_filepath_item, arcname)
        
        # L∆∞u th√¥ng tin ZIP v√†o session ƒë·ªÉ download sau
        session['extract_zip'] = {
            'path': zip_filepath,
            'display_name': zip_display_name,
            'input_path': filepath,
            'json_files': json_files,
            'temp_dir': temp_dir
        }
        
        # T√≠nh to√°n dedup data (g·ªôp keys c√≥ c√πng value)
        dedup_files, dedup_mapping, dedup_stats = build_dedup_data(extracted_data, CHUNK_SIZE)

        # L∆∞u dedup mapping v√†o session folder ƒë·ªÉ d√πng khi inject
        dedup_mapping_path = os.path.join(session_folder, 'dedup_mapping.json')
        with open(dedup_mapping_path, 'w', encoding='utf-8') as f:
            json.dump(dedup_mapping, f, ensure_ascii=False, indent=2)

        # Tr·∫£ v·ªÅ JSON response v·ªõi danh s√°ch file ƒë·ªÉ frontend hi·ªÉn th·ªã
        return jsonify({
            'success': True,
            'total_files': num_files,
            'total_items': total_items,
            'files': files_data,
            'zip_display_name': zip_display_name,
            'dedup_files': dedup_files,
            'dedup_stats': dedup_stats
        })
        
    except Exception as e:
        # X·ª≠ l√Ω l·ªói
        return jsonify({'error': f'L·ªói khi x·ª≠ l√Ω file: {str(e)}'}), 500

@app.route('/download-zip', methods=['GET'])
@login_required
def download_zip():
    """
    Serve file ZIP ƒë√£ ƒë∆∞·ª£c t·∫°o t·ª´ /extract.
    X√≥a t·∫•t c·∫£ file t·∫°m sau khi g·ª≠i xong.
    """
    zip_info = session.get('extract_zip')
    if not zip_info:
        return jsonify({'error': 'Kh√¥ng t√¨m th·∫•y file ZIP. Vui l√≤ng tr√≠ch xu·∫•t l·∫°i.'}), 404
    
    zip_filepath = zip_info.get('path')
    zip_display_name = zip_info.get('display_name', 'download.zip')
    
    if not zip_filepath or not os.path.exists(zip_filepath):
        return jsonify({'error': 'File ZIP kh√¥ng c√≤n t·ªìn t·∫°i. Vui l√≤ng tr√≠ch xu·∫•t l·∫°i.'}), 404
    
    # X√≥a th√¥ng tin ZIP trong session
    session.pop('extract_zip', None)
    
    # Tr·∫£ v·ªÅ file ZIP
    response = send_file(zip_filepath, mimetype='application/zip')
    response = set_download_headers(response, zip_display_name, 'download.zip')
    
    # X√≥a t·∫•t c·∫£ file t·∫°m sau khi g·ª≠i
    input_path = zip_info.get('input_path')
    json_files = zip_info.get('json_files', [])
    temp_dir = zip_info.get('temp_dir')
    
    @response.call_on_close
    def cleanup():
        import time
        import gc
        gc.collect()
        time.sleep(0.1)
        
        try:
            if zip_filepath and os.path.exists(zip_filepath):
                os.remove(zip_filepath)
        except Exception as e:
            print(f"Warning: Kh√¥ng th·ªÉ x√≥a ZIP: {e}")
        
        try:
            if input_path and os.path.exists(input_path):
                os.remove(input_path)
        except Exception as e:
            print(f"Warning: Kh√¥ng th·ªÉ x√≥a input file: {e}")
        
        for jf in json_files:
            try:
                if os.path.exists(jf):
                    os.remove(jf)
            except Exception as e:
                print(f"Warning: Kh√¥ng th·ªÉ x√≥a JSON file: {e}")
        
        try:
            if temp_dir and os.path.exists(temp_dir):
                os.rmdir(temp_dir)
        except Exception as e:
            print(f"Warning: Kh√¥ng th·ªÉ x√≥a temp dir: {e}")
    
    return response

@app.route('/inject', methods=['POST'])
@login_required
def inject():
    """
    Ch·ª©c nƒÉng 2: N·∫°p d·ªØ li·ªáu t·ª´ file JSON ƒë√£ d·ªãch v√†o file Excel, PPTX ho·∫∑c DOCX g·ªëc
    Gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng, m√†u s·∫Øc c·ªßa file g·ªëc
    H·ªó tr·ª£ nhi·ªÅu file JSON ri√™ng l·∫ª ho·∫∑c file ZIP ch·ª©a nhi·ªÅu file JSON
    """
    # Ki·ªÉm tra xem c√≥ file ƒë∆∞·ª£c upload kh√¥ng
    if 'excel_file' not in request.files:
        return jsonify({'error': 'C·∫ßn upload file Excel, PPTX ho·∫∑c DOCX'}), 400
    
    excel_file = request.files['excel_file']
    
    # L·∫•y pasted JSON data n·∫øu c√≥
    pasted_json_data = request.form.get('pasted_json_data', None)
    
    # Ki·ªÉm tra xem c√≥ file JSON ƒë∆∞·ª£c upload ho·∫∑c c√≥ pasted JSON kh√¥ng
    json_files = request.files.getlist('json_files') if 'json_files' in request.files else []
    
    # Ki·ªÉm tra xem c√≥ √≠t nh·∫•t m·ªôt ngu·ªìn JSON
    has_json_files = len(json_files) > 0 and any(f.filename != '' for f in json_files)
    has_pasted_json = pasted_json_data is not None and pasted_json_data.strip() != ''
    
    if not has_json_files and not has_pasted_json:
        return jsonify({'error': 'C·∫ßn upload √≠t nh·∫•t 1 file JSON/ZIP ho·∫∑c paste JSON'}), 400
    
    # Ki·ªÉm tra xem file excel c√≥ ƒë∆∞·ª£c ch·ªçn kh√¥ng
    if excel_file.filename == '':
        return jsonify({'error': 'C·∫ßn ch·ªçn file Excel/PowerPoint/Word'}), 400
    
    # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
    if not allowed_file(excel_file.filename):
        return jsonify({'error': 'File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng .xlsx, .pptx ho·∫∑c .docx'}), 400
    
    try:
        # L·∫•y session folder
        session_folder = get_session_folder()
        
        # L∆∞u t√™n file g·ªëc (gi·ªØ nguy√™n ti·∫øng Nh·∫≠t, k√Ω t·ª± ƒë·∫∑c bi·ªát)
        original_excel_filename = excel_file.filename
        
        # L·∫•y extension t·ª´ t√™n file g·ªëc
        if '.' in original_excel_filename:
            original_ext = original_excel_filename.rsplit('.', 1)[1].lower()
        else:
            return jsonify({'error': 'T√™n file ph·∫£i c√≥ ƒëu√¥i m·ªü r·ªông (.xlsx ho·∫∑c .pptx)'}), 400
        
        # T·∫°o t√™n file t·∫°m an to√†n ho√†n to√†n t·ª´ timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_temp_filename = f"temp_{timestamp}.{original_ext}"
        excel_filepath = os.path.join(session_folder, safe_temp_filename)
        excel_file.save(excel_filepath)
        
        # ƒê·ªçc v√† g·ªôp d·ªØ li·ªáu JSON t·ª´ t·∫•t c·∫£ c√°c file
        json_data = {}
        temp_files = []
        
        for json_file in json_files:
            if json_file.filename == '':
                continue
                
            json_filename = json_file.filename.lower()
            is_zip = json_filename.endswith('.zip')
            is_json = json_filename.endswith('.json')
            
            if not (is_zip or is_json):
                continue
            
            if is_zip:
                # X·ª≠ l√Ω file ZIP
                temp_zip_filename = f"temp_{timestamp}_{secure_filename(json_file.filename)}"
                zip_filepath = os.path.join(session_folder, temp_zip_filename)
                json_file.save(zip_filepath)
                temp_files.append(zip_filepath)
                
                # Gi·∫£i n√©n v√† ƒë·ªçc t·∫•t c·∫£ c√°c file JSON
                with zipfile.ZipFile(zip_filepath, 'r') as zipf:
                    for file_info in zipf.namelist():
                        if file_info.lower().endswith('.json'):
                            with zipf.open(file_info) as f:
                                try:
                                    content = f.read().decode('utf-8')
                                    chunk_data = json.loads(content)
                                    json_data.update(chunk_data)
                                except UnicodeDecodeError:
                                    # Th·ª≠ v·ªõi encoding kh√°c
                                    f.seek(0)
                                    content = f.read().decode('utf-8-sig')
                                    chunk_data = json.loads(content)
                                    json_data.update(chunk_data)
            else:
                # X·ª≠ l√Ω file JSON ƒë∆°n l·∫ª
                try:
                    json_content = json_file.stream.read().decode('utf-8')
                    chunk_data = json.loads(json_content)
                    json_data.update(chunk_data)
                except UnicodeDecodeError:
                    # Th·ª≠ v·ªõi encoding kh√°c n·∫øu UTF-8 th·∫•t b·∫°i
                    json_file.stream.seek(0)
                    json_content = json_file.stream.read().decode('utf-8-sig')
                    chunk_data = json.loads(json_content)
                    json_data.update(chunk_data)
                except json.JSONDecodeError as e:
                    return jsonify({'error': f'File JSON "{json_file.filename}" kh√¥ng h·ª£p l·ªá: {str(e)}'}), 400
        
        # X·ª≠ l√Ω pasted JSON data
        if pasted_json_data:
            try:
                pasted_data_list = json.loads(pasted_json_data)
                
                # pasted_data_list l√† danh s√°ch c√°c JSON objects
                if isinstance(pasted_data_list, list):
                    for idx, pasted_obj in enumerate(pasted_data_list):
                        if isinstance(pasted_obj, dict):
                            json_data.update(pasted_obj)
                        else:
                            return jsonify({'error': f'Pasted JSON #{idx + 1} kh√¥ng ph·∫£i l√† object'}), 400
                else:
                    return jsonify({'error': 'Pasted JSON data ph·∫£i l√† danh s√°ch c√°c objects'}), 400
                    
            except json.JSONDecodeError as e:
                return jsonify({'error': f'Pasted JSON kh√¥ng h·ª£p l·ªá: {str(e)}'}), 400

        # M·ªü r·ªông dedup keys n·∫øu c√≥ (khi user d·ªãch t·ª´ dedup JSON)
        if any(k.startswith('dedup_') for k in json_data):
            json_data = expand_dedup_data(json_data, session_folder)

        # X√°c ƒë·ªãnh lo·∫°i file v√† n·∫°p d·ªØ li·ªáu (d√πng t√™n file g·ªëc)
        file_ext = original_excel_filename.rsplit('.', 1)[1].lower()
        
        if file_ext == 'xlsx':
            # M·ªü file Excel b·∫±ng openpyxl
            workbook = load_workbook(excel_filepath)
            
            # Duy·ªát qua t·ª´ng entry trong JSON
            for key, translated_value in json_data.items():
                # Parse key theo format "SheetName!CellCoordinate"
                if '!' not in key:
                    continue
                
                sheet_name, cell_coordinate = key.split('!', 1)
                
                # Ki·ªÉm tra xem sheet c√≥ t·ªìn t·∫°i kh√¥ng
                if sheet_name not in workbook.sheetnames:
                    continue
                
                # L·∫•y sheet
                sheet = workbook[sheet_name]
                
                # N·∫°p d·ªØ li·ªáu ƒë√£ d·ªãch v√†o cell
                # openpyxl t·ª± ƒë·ªông gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng c·ªßa cell
                sheet[cell_coordinate] = translated_value
            
            # T·∫°o t√™n file output
            base_filename = os.path.splitext(original_excel_filename)[0]  # T√™n g·ªëc v·ªõi ti·∫øng Nh·∫≠t
            
            output_display_name = f"{base_filename}_translated.xlsx"  # T√™n hi·ªÉn th·ªã
            safe_output_filename = f"output_{timestamp}.xlsx"  # T√™n file trong filesystem
            output_filepath = os.path.join(session_folder, safe_output_filename)
            
            # L∆∞u file Excel ƒë√£ ƒë∆∞·ª£c n·∫°p d·ªØ li·ªáu
            workbook.save(output_filepath)
            workbook.close()
            del workbook  # Gi·∫£i ph√≥ng memory
            
            output_mimetype = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        
        elif file_ext == 'pptx':
            # N·∫°p text v√†o PPTX
            prs = inject_text_to_pptx(excel_filepath, json_data)
            
            # T·∫°o t√™n file output
            base_filename = os.path.splitext(original_excel_filename)[0]  # T√™n g·ªëc v·ªõi ti·∫øng Nh·∫≠t
            
            output_display_name = f"{base_filename}_translated.pptx"  # T√™n hi·ªÉn th·ªã
            safe_output_filename = f"output_{timestamp}.pptx"  # T√™n file trong filesystem
            output_filepath = os.path.join(session_folder, safe_output_filename)
            
            # L∆∞u file PPTX ƒë√£ ƒë∆∞·ª£c n·∫°p d·ªØ li·ªáu
            prs.save(output_filepath)
            del prs  # Gi·∫£i ph√≥ng memory
            
            output_mimetype = 'application/vnd.openxmlformats-officedocument.presentationml.presentation'
        
        elif file_ext == 'docx':
            # N·∫°p text v√†o DOCX
            doc = inject_text_to_docx(excel_filepath, json_data)
            
            # T·∫°o t√™n file output
            base_filename = os.path.splitext(original_excel_filename)[0]  # T√™n g·ªëc v·ªõi ti·∫øng Nh·∫≠t
            
            output_display_name = f"{base_filename}_translated.docx"  # T√™n hi·ªÉn th·ªã
            safe_output_filename = f"output_{timestamp}.docx"  # T√™n file trong filesystem
            output_filepath = os.path.join(session_folder, safe_output_filename)
            
            # L∆∞u file DOCX ƒë√£ ƒë∆∞·ª£c n·∫°p d·ªØ li·ªáu
            doc.save(output_filepath)
            del doc  # Gi·∫£i ph√≥ng memory
            
            output_mimetype = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        
        # Tr·∫£ v·ªÅ file ƒë√£ ƒë∆∞·ª£c n·∫°p d·ªØ li·ªáu (d√πng t√™n hi·ªÉn th·ªã)
        response = send_file(
            output_filepath,
            mimetype=output_mimetype
        )
        
        default_ascii_name = 'download.docx' if file_ext == 'docx' else ('download.pptx' if file_ext == 'pptx' else 'download.xlsx')
        response = set_download_headers(response, output_display_name, default_ascii_name)
        
        # X√≥a t·∫•t c·∫£ file t·∫°m sau khi g·ª≠i response
        @response.call_on_close
        def cleanup():
            import time
            import gc
            
            # Force garbage collection ƒë·ªÉ gi·∫£i ph√≥ng file handles
            gc.collect()
            time.sleep(0.1)  # Delay nh·ªè ƒë·ªÉ ƒë·∫£m b·∫£o file ƒë∆∞·ª£c gi·∫£i ph√≥ng
            
            # X√≥a file output
            try:
                if os.path.exists(output_filepath):
                    os.remove(output_filepath)
            except Exception as e:
                print(f"Warning: Kh√¥ng th·ªÉ x√≥a output file: {e}")
            
            # X√≥a file Excel/PPTX/DOCX t·∫°m
            try:
                if os.path.exists(excel_filepath):
                    os.remove(excel_filepath)
            except Exception as e:
                print(f"Warning: Kh√¥ng th·ªÉ x√≥a file t·∫°m: {e}")
            
            # X√≥a t·∫•t c·∫£ file ZIP t·∫°m
            for temp_file in temp_files:
                try:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                except Exception as e:
                    print(f"Warning: Kh√¥ng th·ªÉ x√≥a file ZIP t·∫°m: {e}")
        
        return response
        
    except Exception as e:
        # X·ª≠ l√Ω l·ªói
        return jsonify({'error': f'L·ªói khi x·ª≠ l√Ω file: {str(e)}'}), 500

@app.route('/clear-uploads', methods=['POST'])
@login_required
def clear_uploads():
    """
    X√≥a t·∫•t c·∫£ file trong th∆∞ m·ª•c session hi·ªán t·∫°i
    """
    try:
        session_folder = get_session_folder()
        
        # Ki·ªÉm tra xem th∆∞ m·ª•c c√≥ t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(session_folder):
            return jsonify({'success': True, 'message': 'Kh√¥ng c√≥ file n√†o ƒë·ªÉ x√≥a'}), 200
        
        # ƒê·∫øm s·ªë file ƒë√£ x√≥a
        deleted_count = 0
        
        # Duy·ªát qua t·∫•t c·∫£ file trong session folder
        for item in os.listdir(session_folder):
            item_path = os.path.join(session_folder, item)
            
            try:
                if os.path.isfile(item_path):
                    # X√≥a file
                    os.remove(item_path)
                    deleted_count += 1
                elif os.path.isdir(item_path):
                    # X√≥a th∆∞ m·ª•c con v√† t·∫•t c·∫£ n·ªôi dung b√™n trong
                    shutil.rmtree(item_path)
                    deleted_count += 1
            except Exception as e:
                print(f"Kh√¥ng th·ªÉ x√≥a {item_path}: {str(e)}")
        
        return jsonify({
            'success': True,
            'message': f'ƒê√£ x√≥a th√†nh c√¥ng {deleted_count} file trong phi√™n c·ªßa b·∫°n',
            'deleted_count': deleted_count
        }), 200
        
    except Exception as e:
        return jsonify({'error': f'L·ªói khi x√≥a file: {str(e)}'}), 500

# ƒê·∫£m b·∫£o th∆∞ m·ª•c uploads t·ªìn t·∫°i
if not os.path.exists(app.config['UPLOAD_FOLDER']):
    os.makedirs(app.config['UPLOAD_FOLDER'])

if __name__ == '__main__':
    # Ch·∫°y ·ª©ng d·ª•ng Flask ·ªü ch·∫ø ƒë·ªô debug
    app.run(debug=True, host='0.0.0.0', port=5001)
